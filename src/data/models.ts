export type ModelArchitecture = "Dense" | "MoE" | "Hybrid Linear" | "Hybrid MoE";
export type OpenSourceStatus = "Open Source" | "Open Weights" | "Proprietary";

export interface ModelData {
    id: string;
    name: string;
    architecture: ModelArchitecture;
    params: number; // Total parameters in billions
    active_params: number; // Active parameters in billions
    context_window: number; // Tokens in thousands
    reasoning: boolean;
    visual: boolean;
    open_source: OpenSourceStatus;
    speed: number | null; // Output speed (tokens per second), null for n/a
    memory: {
        q16: number; // GB (Q16 quantization)
        q8?: number | null; // GB (Q8 quantization)
        q4?: number | null; // GB (Q4 quantization)
        sfp8?: number | null; // GB (SFP8 quantization)
        mxfp4?: number | null; // GB (MXFP4 quantization)
    };
    kv_cache_per_100k_tokens: number; // GB per 100k tokens (FP16)
    benchmarks: {
        aa_lcr?: number | null; // AA-LCR (Long Context Reasoning)
        aa_omniscience_accuracy?: number | null;
        aa_omniscience_non_hallucination?: number | null;
        ifbench?: number | null;
        mmmu_pro?: number | null; // Visual Reasoning
    };
}

export const MODELS: ModelData[] = [
    {
        id: "gpt-oss-120b",
        name: "gpt-oss-120b",
        architecture: "MoE",
        params: 117,
        active_params: 5,
        context_window: 131,
        reasoning: true,
        visual: false,
        open_source: "Open Source",
        speed: 338,
        memory: { q16: 65, q8: 63, q4: 63, mxfp4: 63 },
        kv_cache_per_100k_tokens: 6.87,
        benchmarks: { aa_lcr: 51, aa_omniscience_accuracy: 20, aa_omniscience_non_hallucination: 10, ifbench: 69 }
    },
    {
        id: "llama-4-scout",
        name: "Llama 4 Scout",
        architecture: "MoE",
        params: 109,
        active_params: 17,
        context_window: 10000,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: null,
        memory: { q16: 256, q8: 113, q4: 68 },
        kv_cache_per_100k_tokens: 18.31,
        benchmarks: { aa_lcr: 26, aa_omniscience_accuracy: 14, aa_omniscience_non_hallucination: 21, ifbench: 40, mmmu_pro: 53 }
    },
    {
        id: "glm-4.5-air",
        name: "GLM-4.5-Air",
        architecture: "MoE",
        params: 106,
        active_params: 12,
        context_window: 128,
        reasoning: true,
        visual: false,
        open_source: "Open Source",
        speed: 119,
        memory: { q16: 221, q8: 117, q4: 74 },
        kv_cache_per_100k_tokens: 17.55,
        benchmarks: { aa_lcr: 44, aa_omniscience_accuracy: 15, aa_omniscience_non_hallucination: 8, ifbench: 38 }
    },
    {
        id: "ring-flash-2.0",
        name: "Ring-flash-2.0",
        architecture: "Hybrid Linear",
        params: 103,
        active_params: 6,
        context_window: 128,
        reasoning: true,
        visual: false,
        open_source: "Open Source",
        speed: 97,
        memory: { q16: 206, q8: 110, q4: 62, mxfp4: 62 },
        kv_cache_per_100k_tokens: 6.10,
        benchmarks: { aa_lcr: 21, aa_omniscience_accuracy: 16, aa_omniscience_non_hallucination: 11, ifbench: 43 }
    },
    {
        id: "ling-flash-2.0",
        name: "Ling-flash-2.0",
        architecture: "MoE",
        params: 103,
        active_params: 6,
        context_window: 128,
        reasoning: false,
        visual: false,
        open_source: "Open Source",
        speed: 73,
        memory: { q16: 206, q8: 110, q4: 62, mxfp4: 62 },
        kv_cache_per_100k_tokens: 6.10,
        benchmarks: { aa_lcr: 15, aa_omniscience_accuracy: 14, aa_omniscience_non_hallucination: 6, ifbench: 34 }
    },
    {
        id: "qwen3-next-80b",
        name: "Qwen3 Next 80B",
        architecture: "Hybrid Linear",
        params: 80,
        active_params: 3,
        context_window: 262,
        reasoning: true,
        visual: false,
        open_source: "Open Weights",
        speed: 172,
        memory: { q16: 160, q8: 85, q4: 48 },
        kv_cache_per_100k_tokens: 2.29,
        benchmarks: { aa_lcr: 51, aa_omniscience_accuracy: 17, aa_omniscience_non_hallucination: 7, ifbench: 40 }
    },
    {
        id: "deepseek-r1-70b",
        name: "DeepSeek R1 70B",
        architecture: "Dense",
        params: 70,
        active_params: 70,
        context_window: 128,
        reasoning: true,
        visual: false,
        open_source: "Open Weights",
        speed: 42,
        memory: { q16: 142, q8: 75, q4: 43 },
        kv_cache_per_100k_tokens: 30.52,
        benchmarks: { aa_lcr: 11, aa_omniscience_accuracy: 19, aa_omniscience_non_hallucination: 19, ifbench: 28 }
    },
    {
        id: "llama-3.3-70b",
        name: "Llama 3.3 70B",
        architecture: "Dense",
        params: 70,
        active_params: 70,
        context_window: 128,
        reasoning: false,
        visual: false,
        open_source: "Open Weights",
        speed: 140,
        memory: { q16: 141, q8: 75, q4: 43 },
        kv_cache_per_100k_tokens: 30.52,
        benchmarks: { aa_lcr: 15, aa_omniscience_accuracy: 18, aa_omniscience_non_hallucination: 11, ifbench: 47 }
    },
    {
        id: "llama-3.1-70b",
        name: "Llama 3.1 70B",
        architecture: "Dense",
        params: 70,
        active_params: 70,
        context_window: 128,
        reasoning: false,
        visual: false,
        open_source: "Open Weights",
        speed: 44,
        memory: { q16: 141, q8: 75, q4: 43 },
        kv_cache_per_100k_tokens: 30.52,
        benchmarks: { aa_lcr: 7, aa_omniscience_accuracy: 16, aa_omniscience_non_hallucination: 31, ifbench: 31 }
    },
    {
        id: "kimi-linear",
        name: "Kimi Linear",
        architecture: "Hybrid Linear",
        params: 49,
        active_params: 3,
        context_window: 1000,
        reasoning: false,
        visual: false,
        open_source: "Open Source",
        speed: null,
        memory: { q16: 103, q8: 54, q4: 29, mxfp4: 29 },
        kv_cache_per_100k_tokens: 10.68,
        benchmarks: { aa_lcr: 26, ifbench: 28 }
    },
    {
        id: "qwen3-vl-32b",
        name: "Qwen3 VL 32B",
        architecture: "Dense",
        params: 33,
        active_params: 33,
        context_window: 262,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 90,
        memory: { q16: 66, q8: 35, q4: 20 },
        kv_cache_per_100k_tokens: 24.41,
        benchmarks: { aa_lcr: 31, aa_omniscience_accuracy: 14, aa_omniscience_non_hallucination: 9, ifbench: 39, mmmu_pro: 64 }
    },
    {
        id: "granite-4.0-hsmall",
        name: "Granite 4.0 HSmall",
        architecture: "Hybrid MoE",
        params: 32,
        active_params: 9,
        context_window: 128,
        reasoning: false,
        visual: false,
        open_source: "Open Source",
        speed: 454,
        memory: { q16: 64, q8: 34, q4: 19, mxfp4: 10 },
        kv_cache_per_100k_tokens: 1.53,
        benchmarks: { aa_lcr: 9, aa_omniscience_accuracy: 13, aa_omniscience_non_hallucination: 13, ifbench: 32 }
    },
    {
        id: "nvidia-nemotron-3-nano-30b",
        name: "NVIDIA Nemotron 3 Nano 30B",
        architecture: "MoE",
        params: 32,
        active_params: 4,
        context_window: 1000,
        reasoning: true,
        visual: false,
        open_source: "Open Weights",
        speed: 189,
        memory: { q16: 60, q8: 32, q4: 21 },
        kv_cache_per_100k_tokens: 0.57,
        benchmarks: { aa_lcr: 7, aa_omniscience_accuracy: 13, aa_omniscience_non_hallucination: 10, ifbench: 38 }
    },
    {
        id: "glm-4.7-flash",
        name: "GLM-4.7-Flash",
        architecture: "MoE",
        params: 31,
        active_params: 3,
        context_window: 200,
        reasoning: false,
        visual: false,
        open_source: "Open Source",
        speed: 114,
        memory: { q16: 60, q8: 36, q4: 20, mxfp4: 18 },
        kv_cache_per_100k_tokens: 22.41,
        benchmarks: { aa_lcr: 15, aa_omniscience_accuracy: 12, aa_omniscience_non_hallucination: 6, ifbench: 46 }
    },
    {
        id: "qwen3-coder-30b",
        name: "Qwen3 Coder 30B",
        architecture: "MoE",
        params: 31,
        active_params: 3,
        context_window: 262,
        reasoning: false,
        visual: false,
        open_source: "Open Weights",
        speed: 111,
        memory: { q16: 61, q8: 32, q4: 19 },
        kv_cache_per_100k_tokens: 9.16,
        benchmarks: { aa_lcr: 29, aa_omniscience_accuracy: 15, aa_omniscience_non_hallucination: 21, ifbench: 33 }
    },
    {
        id: "qwen3-30b",
        name: "Qwen3 30B",
        architecture: "MoE",
        params: 31,
        active_params: 3,
        context_window: 262,
        reasoning: false,
        visual: false,
        open_source: "Open Weights",
        speed: 75,
        memory: { q16: 60, q8: 32, q4: 18 },
        kv_cache_per_100k_tokens: 9.16,
        benchmarks: { aa_lcr: 23, aa_omniscience_accuracy: 14, aa_omniscience_non_hallucination: 5, ifbench: 33 }
    },
    {
        id: "qwen3-vl-30b",
        name: "Qwen3 VL 30B",
        architecture: "MoE",
        params: 30,
        active_params: 3,
        context_window: 262,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 117,
        memory: { q16: 60, q8: 32, q4: 19 },
        kv_cache_per_100k_tokens: 9.16,
        benchmarks: { aa_lcr: 24, aa_omniscience_accuracy: 15, aa_omniscience_non_hallucination: 8, ifbench: 33, mmmu_pro: 62 }
    },
    {
        id: "gemma-3-27b",
        name: "Gemma 3 27B",
        architecture: "Dense",
        params: 27,
        active_params: 27,
        context_window: 128,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 46,
        memory: { q16: 54, q8: 29, q4: 17, sfp8: 27 },
        kv_cache_per_100k_tokens: 47.30,
        benchmarks: { aa_lcr: 6, aa_omniscience_accuracy: 12, aa_omniscience_non_hallucination: 9, ifbench: 32, mmmu_pro: 48 }
    },
    {
        id: "devstral-small-2",
        name: "Devstral Small 2",
        architecture: "Dense",
        params: 24,
        active_params: 24,
        context_window: 262,
        reasoning: false,
        visual: false,
        open_source: "Open Source",
        speed: 209,
        memory: { q16: 48, q8: 26, q4: 14 },
        kv_cache_per_100k_tokens: 15.26,
        benchmarks: { aa_lcr: 24, aa_omniscience_accuracy: 15, aa_omniscience_non_hallucination: 13, ifbench: 31 }
    },
    {
        id: "mistral-small-3.2",
        name: "Mistral Small 3.2",
        architecture: "Dense",
        params: 24,
        active_params: 24,
        context_window: 128,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 147,
        memory: { q16: 67, q8: 36, q4: 20, mxfp4: 18 },
        kv_cache_per_100k_tokens: 15.26,
        benchmarks: { aa_lcr: 17, aa_omniscience_accuracy: 14, aa_omniscience_non_hallucination: 24, ifbench: 34, mmmu_pro: 48 }
    },
    {
        id: "gpt-oss-20b",
        name: "gpt-oss-20b",
        architecture: "MoE",
        params: 21,
        active_params: 4,
        context_window: 131,
        reasoning: true,
        visual: false,
        open_source: "Open Source",
        speed: 308,
        memory: { q16: 14, q8: 12, q4: 12, mxfp4: 11 },
        kv_cache_per_100k_tokens: 4.58,
        benchmarks: { aa_lcr: 31, aa_omniscience_accuracy: 15, aa_omniscience_non_hallucination: 7, ifbench: 65 }
    },
    {
        id: "apriel-v1.6",
        name: "Apriel-v1.6",
        architecture: "Dense",
        params: 15,
        active_params: 15,
        context_window: 128,
        reasoning: true,
        visual: true,
        open_source: "Open Weights",
        speed: 156,
        memory: { q16: 30, q8: 16, q4: 9 },
        kv_cache_per_100k_tokens: 19.07,
        benchmarks: { aa_lcr: 50, aa_omniscience_accuracy: 17, aa_omniscience_non_hallucination: 8, ifbench: 69 }
    },
    {
        id: "ministral-3-14b",
        name: "Ministral 3 14B",
        architecture: "Dense",
        params: 14,
        active_params: 14,
        context_window: 262,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 148,
        memory: { q16: 28, q8: 15, q4: 9 },
        kv_cache_per_100k_tokens: 15.26,
        benchmarks: { aa_lcr: 22, aa_omniscience_accuracy: 12, aa_omniscience_non_hallucination: 10, ifbench: 32, mmmu_pro: 50 }
    },
    {
        id: "phi-4",
        name: "Phi-4",
        architecture: "Dense",
        params: 14,
        active_params: 14,
        context_window: 16,
        reasoning: false,
        visual: true,
        open_source: "Open Source",
        speed: 17,
        memory: { q16: 11, q8: 6, q4: 3 },
        kv_cache_per_100k_tokens: 12.21,
        benchmarks: { aa_omniscience_accuracy: 13, aa_omniscience_non_hallucination: 21, ifbench: 24 }
    },
    {
        id: "nvidia-nemotron-nano-13b",
        name: "NVIDIA Nemotron Nano 13B",
        architecture: "Dense",
        params: 13,
        active_params: 13,
        context_window: 128,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 137,
        memory: { q16: 24, q8: 13, q4: 21, mxfp4: 24 },
        kv_cache_per_100k_tokens: 3.81,
        benchmarks: { aa_lcr: 17, aa_omniscience_accuracy: 11, aa_omniscience_non_hallucination: 6, ifbench: 26, mmmu_pro: 45 }
    },
    {
        id: "gemma-3-12b",
        name: "Gemma 3 12B",
        architecture: "Dense",
        params: 12,
        active_params: 12,
        context_window: 128,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 44,
        memory: { q16: 24, q8: 15, q4: 8, sfp8: 12 },
        kv_cache_per_100k_tokens: 34.33,
        benchmarks: { aa_lcr: 7, aa_omniscience_accuracy: 10, aa_omniscience_non_hallucination: 3, ifbench: 37, mmmu_pro: 38 }
    },
    {
        id: "llama-3.2-11b",
        name: "Llama 3.2 11B",
        architecture: "Dense",
        params: 11,
        active_params: 11,
        context_window: 128,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 77,
        memory: { q16: 22, q8: 12, q4: 7 },
        kv_cache_per_100k_tokens: 12.21,
        benchmarks: { aa_lcr: 12, aa_omniscience_accuracy: 10, aa_omniscience_non_hallucination: 20, ifbench: 30, mmmu_pro: 29 }
    },
    {
        id: "nvidia-nemotron-nano-9b",
        name: "NVIDIA Nemotron Nano 9B",
        architecture: "Dense",
        params: 9,
        active_params: 9,
        context_window: 131,
        reasoning: true,
        visual: false,
        open_source: "Open Weights",
        speed: 121,
        memory: { q16: 17, q8: 9, q4: 6 },
        kv_cache_per_100k_tokens: 1.53,
        benchmarks: { aa_lcr: 23, aa_omniscience_accuracy: 9, aa_omniscience_non_hallucination: 26, ifbench: 27 }
    },
    {
        id: "qwen3-vl-8b",
        name: "Qwen3 VL 8B",
        architecture: "Dense",
        params: 9,
        active_params: 9,
        context_window: 262,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 97,
        memory: { q16: 15, q8: 8, q4: 5 },
        kv_cache_per_100k_tokens: 13.73,
        benchmarks: { aa_lcr: 15, aa_omniscience_accuracy: 19, aa_omniscience_non_hallucination: 10, ifbench: 32, mmmu_pro: 47 }
    },
    {
        id: "deepseek-r1-8b",
        name: "DeepSeek R1 8B",
        architecture: "Dense",
        params: 8,
        active_params: 8,
        context_window: 33,
        reasoning: true,
        visual: false,
        open_source: "Open Source",
        speed: null,
        memory: { q16: 16, q8: 9, q4: 5 },
        kv_cache_per_100k_tokens: 12.21,
        benchmarks: { aa_lcr: 13, aa_omniscience_accuracy: 11, aa_omniscience_non_hallucination: 14, ifbench: 20 }
    },
    {
        id: "ministral-3-8b",
        name: "Ministral 3 8B",
        architecture: "Dense",
        params: 8,
        active_params: 8,
        context_window: 262,
        reasoning: false,
        visual: true,
        open_source: "Open Weights",
        speed: 193,
        memory: { q16: 16, q8: 9, q4: 5 },
        kv_cache_per_100k_tokens: 13.73,
        benchmarks: { aa_lcr: 24, aa_omniscience_accuracy: 12, aa_omniscience_non_hallucination: 7, ifbench: 29, mmmu_pro: 46 }
    }
];
